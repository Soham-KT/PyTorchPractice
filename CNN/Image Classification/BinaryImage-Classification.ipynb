{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shanks/data-science/PyTorchPractice/CNN/Image Classification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainset = torchvision.datasets.ImageFolder(root='Data-binary/train', transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testset = torchvision.datasets.ImageFolder(root='Data-binary/test', transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "classes = ['Positive', 'Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Negative \n",
      "Negative Positive\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img, lab):\n",
    "    img = img / 2 + 0.5    \n",
    "    npimg = img.numpy()\n",
    "    print(classes[lab[0]], classes[lab[1]],'\\n'+ classes[lab[2]], classes[lab[3]])\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=2), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassificationNet()      \n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, Step 1/250,Loss: 0.6953\n",
      "Epoch 0/10, Step 101/250,Loss: 0.6778\n",
      "Epoch 0/10, Step 201/250,Loss: 0.6928\n",
      "Epoch 1/10, Step 1/250,Loss: 0.6815\n",
      "Epoch 1/10, Step 101/250,Loss: 0.6915\n",
      "Epoch 1/10, Step 201/250,Loss: 0.6989\n",
      "Epoch 2/10, Step 1/250,Loss: 0.6944\n",
      "Epoch 2/10, Step 101/250,Loss: 0.6890\n",
      "Epoch 2/10, Step 201/250,Loss: 0.6866\n",
      "Epoch 3/10, Step 1/250,Loss: 0.6813\n",
      "Epoch 3/10, Step 101/250,Loss: 0.6800\n",
      "Epoch 3/10, Step 201/250,Loss: 0.6888\n",
      "Epoch 4/10, Step 1/250,Loss: 0.6811\n",
      "Epoch 4/10, Step 101/250,Loss: 0.6761\n",
      "Epoch 4/10, Step 201/250,Loss: 0.6662\n",
      "Epoch 5/10, Step 1/250,Loss: 0.6539\n",
      "Epoch 5/10, Step 101/250,Loss: 0.6839\n",
      "Epoch 5/10, Step 201/250,Loss: 0.6554\n",
      "Epoch 6/10, Step 1/250,Loss: 0.6395\n",
      "Epoch 6/10, Step 101/250,Loss: 0.6937\n",
      "Epoch 6/10, Step 201/250,Loss: 0.5256\n",
      "Epoch 7/10, Step 1/250,Loss: 0.5135\n",
      "Epoch 7/10, Step 101/250,Loss: 0.4595\n",
      "Epoch 7/10, Step 201/250,Loss: 0.3482\n",
      "Epoch 8/10, Step 1/250,Loss: 0.4502\n",
      "Epoch 8/10, Step 101/250,Loss: 0.5283\n",
      "Epoch 8/10, Step 201/250,Loss: 0.8367\n",
      "Epoch 9/10, Step 1/250,Loss: 0.2925\n",
      "Epoch 9/10, Step 101/250,Loss: 0.1697\n",
      "Epoch 9/10, Step 201/250,Loss: 0.2042\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_fn(outputs, labels.reshape(-1, 1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch}/{NUM_EPOCHS}, Step {i+1}/{len(trainloader)},' f'Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test_pred = []\n",
    "for i, data in enumerate(testloader):\n",
    "    inputs, y_test_temp = data\n",
    "    with torch.no_grad():\n",
    "        y_test_hat_temp = model(inputs).round()\n",
    "    \n",
    "    y_test.extend(y_test_temp.numpy())\n",
    "    y_test_pred.extend(y_test_hat_temp.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  87.83%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Accuracy: {acc*100: .2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 15:46:34.565236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-18 15:46:34.579108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-18 15:46:34.582839: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 15:46:34.594213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 15:46:35.320453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected an object of type `Trackable`, such as `tf.Module` or a subclass of the `Trackable` class, for export. Got ImageClassificationNet(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=1, bias=True)\n  (relu): ReLU()\n  (sigmoid): Sigmoid()\n) with type <class '__main__.ImageClassificationNet'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSasta-Model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1432\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1432\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1467\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1463\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1464\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1466\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1467\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1468\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1469\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1682\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1583\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base\u001b[38;5;241m.\u001b[39mTrackable):\n\u001b[0;32m-> 1583\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1584\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected an object of type `Trackable`, such as `tf.Module` or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1585\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubclass of the `Trackable` class, for export. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1586\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1587\u001b[0m   )\n\u001b[1;32m   1588\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m meta_graph_def \u001b[38;5;129;01mor\u001b[39;00m meta_graph_pb2\u001b[38;5;241m.\u001b[39mMetaGraphDef()\n\u001b[1;32m   1590\u001b[0m augmented_graph_view \u001b[38;5;241m=\u001b[39m _AugmentedGraphView(obj)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected an object of type `Trackable`, such as `tf.Module` or a subclass of the `Trackable` class, for export. Got ImageClassificationNet(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=1, bias=True)\n  (relu): ReLU()\n  (sigmoid): Sigmoid()\n) with type <class '__main__.ImageClassificationNet'>."
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'Sasta-Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model.pb. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model.pb, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the Keras model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model.pb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert the model to TensorFlow Lite format\u001b[39;00m\n\u001b[1;32m      5\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/saving/saving_api.py:199\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model.pb. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model.pb, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the TensorFlow SavedModel\n",
    "model = tf.saved_model.load('/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model')\n",
    "\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optional: Apply optimization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convert and save the model\n",
    "tflite_model = converter.convert()\n",
    "with open('/home/shanks/data-science/PyTorchPractice/CNN/Image Classification/sasta_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
